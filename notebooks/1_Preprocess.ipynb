{
 "cells": [
  {
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this notebook the initial preprocessing of the provided data set will be done. Firstly the needed packages are imported and the raw dataframe is loaded:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from geopy.exc import GeocoderTimedOut \n",
    "from geopy.geocoders import Nominatim \n",
    "import pycountry_convert as pc\n",
    "\n",
    "# Read data frame\n",
    "df = pd.read_excel(os.path.abspath('../data/Raw/Cities.xls'), index_col=0)"
   ]
  },
  {
   "source": [
    "## Replacing spaces with underscores\n",
    "\n",
    "In the column names a lot of spaces are found. They are in general not nice to work with coding wise why all spaces are replaced with underscores in the column names:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Add _ instead of space\n",
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "source": [
    "## Fixing object columns\n",
    "\n",
    "Two columns in the date are object columns due to the fact that are few cells that should be empty - i.e. nan - have a space. `Pandas` then interprets this as a object even thouhgh the column should be nummeric. This is fixed below, where the argument `errors='coerce'`ensures that the spaces are turned into nan as it should be:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bikeshare_Stations'] = pd.to_numeric(df['Bikeshare_Stations'], errors='coerce')\n",
    "df['Bicycle_Modeshare_(%)'] = pd.to_numeric(df['Bicycle_Modeshare_(%)'], errors='coerce')"
   ]
  },
  {
   "source": [
    "## Getting longitude and latitude\n",
    "\n",
    "As the data is based on cities it could be interesting to an overview of their location. Therefor the longitude and latitude for all cities are added using the `geopy`. The cell below take some time to run due to the number of API calls made."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists\n",
    "longitude = [] \n",
    "latitude = [] \n",
    "   \n",
    "# function to find the coordinate of a given city using Geopy\n",
    "def findGeocode(city): \n",
    "       \n",
    "    # try and catch is used to overcome \n",
    "    # the exception thrown by geolocator   \n",
    "    try:\n",
    "        geolocator = Nominatim(user_agent=\"VS\")   \n",
    "        return geolocator.geocode(city) \n",
    "      \n",
    "    except GeocoderTimedOut: \n",
    "        return findGeocode(city)\n",
    "    \n",
    "    except GeocoderUnavailable:\n",
    "        return findGeocode(city)\n",
    "  \n",
    "# Apply the function to all cities in the data.\n",
    "for _, row in df[[\"City\",\"Country\"]].iterrows():\n",
    "      \n",
    "    if findGeocode(row[\"City\"]+', '+ row[\"Country\"]) != None: \n",
    "           \n",
    "        loc = findGeocode(row[\"City\"]+', '+ row[\"Country\"]) \n",
    "          \n",
    "        # coordinates returned from the function is appended to the list.\n",
    "        latitude.append(loc.latitude) \n",
    "        longitude.append(loc.longitude) \n",
    "       \n",
    "    # Insert nan if the city is not found  \n",
    "    else: \n",
    "        latitude.append(np.nan) \n",
    "        longitude.append(np.nan)"
   ]
  },
  {
   "source": [
    "It is now checked if there are any cities that `Geopy` missed:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The index of the missing cities are [ 68 102 103 132 155], and they are:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "282           Denver-Aurora(CO)\n325               Valencia(VZL)\n143            Osaka-Kobe-Kyoto\n281    Minneapolis-St. Paul(MN)\n283    Tampa-St. Petersburg(FL)\nName: City, dtype: object"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "print(f\"The index of the missing cities are {np.argwhere(np.isnan(latitude)).reshape(-1)}, and they are:\")\n",
    "df.iloc[np.argwhere(np.isnan(latitude)).reshape(-1)].City"
   ]
  },
  {
   "source": [
    "There are two cities only. They can easily be added manually (by looking them up at Google) as done below before appending the new columns to the dataframe. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the two missing manually\n",
    "latitude[102], longitude[102] = 10.156421, -67.999718 #Valencia(VZL)\n",
    "latitude[155], longitude[155] = 27.773056, -82.639999 #Tampa-St. Petersburg(FL)\n",
    "\n",
    "# Add columns to data frame\n",
    "df[\"Latitude\"] = np.array(latitude)\n",
    "df[\"Longitude\"] = np.array(longitude)"
   ]
  },
  {
   "source": [
    "## Adding continent\n",
    "\n",
    "The continent of all cities are also added. This is primarily so the data can be split baed on continent as it is desired for one part of the prediction challenge."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_to_continent(country_name):\n",
    "    # Get two-letter abbriviation for all countries\n",
    "    country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "\n",
    "    # Get continent code\n",
    "    country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "\n",
    "    # Get continent name from continent code\n",
    "    country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "    return country_continent_name\n",
    "\n",
    "# Get continent for all countried\n",
    "df['Continent'] = [country_to_continent(con) for con in df.Country]"
   ]
  },
  {
   "source": [
    "## Returning the processed dataframe\n",
    "\n",
    "The preprocessed dataframe is now returned as a csv to the processed folder:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return file\n",
    "df.to_csv(os.path.abspath('../data/Processed/Cities.csv'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitbachallengeconda85e1423268dc40b2b3ee88553ec51b6e",
   "display_name": "Python 3.7.9 64-bit ('BA_challenge': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4ac9127a5e3a2f46c2a2e8821ed18a7311c7b82158d93cf3bc56b999ae4e532f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}